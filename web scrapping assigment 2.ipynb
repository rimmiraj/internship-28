{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d068e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing of lib.\n",
    "#!pip install selenium\n",
    "#Importing Lib\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1266078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open the chromedriver\n",
    "driver = webdriver.Chrome(r\"E:\\cromedriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd936e9c",
   "metadata": {},
   "source": [
    "Ques. 1\n",
    "Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "First get the webpage https://www.naukri.com/\n",
    "Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "Then click the search button.\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "698bcf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3948e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job = driver.find_element_by_class_name(\"suggestor-input \")#extracting element\n",
    "search_job.send_keys(\"Data Analyst\")#Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bab5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_locn = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')#extracting element\n",
    "search_locn.send_keys(\"Bangalore\")#Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "295d4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[3]/div/div/div[6]')#extracting element\n",
    "search_btn.click()#Clicking on the seach bbutton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47346d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "title_tags = [] #empty list\n",
    "location = []\n",
    "company = []\n",
    "exper = []\n",
    "\n",
    "tit = driver.find_elements_by_xpath('//a[@class = \"title fw500 ellipsis\"]')\n",
    "title = tit[0:10]    #fixing the boundries(how much data we want to extract)\n",
    "loc = driver.find_elements_by_xpath('//li[@class = \"fleft grey-text br2 placeHolderLi location\"]')\n",
    "locc = loc[0:10]    \n",
    "com = driver.find_elements_by_xpath('//a[@class = \"subTitle ellipsis fleft\"]')\n",
    "comp = com[0:10]    \n",
    "exp = driver.find_elements_by_xpath('//li[@class = \"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "expp = exp[0:10]   \n",
    "\n",
    "for i in title:\n",
    "    title_tags.append(i.text) #appending the text in Title_tags list\n",
    "print(len(title_tags))\n",
    "for j in locc:\n",
    "    location.append(j.text) #Fetching text data\n",
    "print(len(location))\n",
    "for k in comp:\n",
    "    company.append(k.text)\n",
    "print(len(company))\n",
    "for l in expp:\n",
    "    exper.append(l.text)\n",
    "print(len(exper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ea587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fed8c675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr.Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, karnataka\\n(WFH during Co...</td>\n",
       "      <td>Collabera</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hudsons bay Company (HBC)</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - IIM/ISB/MDI/FMS/SP Jain</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>K12 Techno Services Pvt Ltd</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Analyst/Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, D...</td>\n",
       "      <td>Telamon HR Solutions</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job Title  \\\n",
       "0                 Sr.Business Data Analyst   \n",
       "1                      Senior Data Analyst   \n",
       "2                      Senior Data Analyst   \n",
       "3  Master Data Management Business Analyst   \n",
       "4                          Sr Data Analyst   \n",
       "5   Data Analyst - IIM/ISB/MDI/FMS/SP Jain   \n",
       "6            Business Analyst/Data Analyst   \n",
       "7                  Hiring For Data Analyst   \n",
       "8                             Data Analyst   \n",
       "9                   Associate Data Analyst   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Bangalore/Bengaluru, karnataka\\n(WFH during Co...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2               Bangalore/Bengaluru(Old Madras Road)   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Bangalore/Bengaluru, Hyderabad/Secunderabad, D...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                  Company Name Experience Required  \n",
       "0                    Collabera            6-11 Yrs  \n",
       "1    Hudsons bay Company (HBC)             3-4 Yrs  \n",
       "2                     KrazyBee             3-6 Yrs  \n",
       "3                    Accenture             6-8 Yrs  \n",
       "4              Thomson Reuters             5-8 Yrs  \n",
       "5  K12 Techno Services Pvt Ltd             4-9 Yrs  \n",
       "6         Telamon HR Solutions             3-5 Yrs  \n",
       "7                     Flipkart             2-5 Yrs  \n",
       "8                        Wipro             4-9 Yrs  \n",
       "9                        Optum             2-7 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame() #Creating dataframe\n",
    "df['Job Title'] = title_tags\n",
    "df['Job Location'] = location\n",
    "df['Company Name'] = company\n",
    "df['Experience Required'] = exper\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd48ea99",
   "metadata": {},
   "source": [
    "Ques. 2\n",
    "Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "First get the webpage https://www.naukri.com/\n",
    "Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "Then click the search button.\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6ad594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url1 = 'https://www.naukri.com/'\n",
    "driver.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4012f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job1 = driver.find_element_by_class_name(\"suggestor-input \")#extracting element\n",
    "search_job1.send_keys(\"Data Scientist\") #Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f74f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_locn1 = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_locn1.send_keys(\"Bangalore\")#Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44b8bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn1 = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35ccc03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "title_tags1 = []\n",
    "location1 = []\n",
    "company1 = []\n",
    "\n",
    "title_tag1 = driver.find_elements_by_xpath('//a[@class = \"title fw500 ellipsis\"]')\n",
    "title1=title_tag1[0:10] #fixing the boundries(how much data we want to extract)\n",
    "loc1 = driver.find_elements_by_xpath('//li[@class = \"fleft grey-text br2 placeHolderLi location\"]')\n",
    "locc1 = loc1[0:10]\n",
    "com1 = driver.find_elements_by_xpath('//a[@class = \"subTitle ellipsis fleft\"]')\n",
    "comp1 = com1[0:10]\n",
    "\n",
    "for i in title1:\n",
    "    title_tags1.append(i.text)#appending the text in Title_tags list\n",
    "for j in locc1:\n",
    "    location1.append(j.text) #Fetching location data\n",
    "for k in comp1:\n",
    "    company1.append(k.text) \n",
    "    \n",
    "print(len(title_tags1)) #priting title_tags1\n",
    "print(len(location1))\n",
    "print(len(company1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd3e5756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>InnovAccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IHS Markit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data &amp; Analytics Tech - Informatica Cloud- Sen...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dataiku Consultant</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Research and Development -AI/ML -(PhD )</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>EXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Opportunity For Data Scientist - Female Candid...</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "1                   Hiring For Senior Data Scientist   \n",
       "2                              Senior Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5  Data & Analytics Tech - Informatica Cloud- Sen...   \n",
       "6                                 Dataiku Consultant   \n",
       "7            Research and Development -AI/ML -(PhD )   \n",
       "8  Opportunity For Data Scientist - Female Candid...   \n",
       "9                       Senior Data Science Engineer   \n",
       "\n",
       "                                        Job Location  \\\n",
       "0  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "1                          Bangalore/Bengaluru, Pune   \n",
       "2  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "7  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "8  Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...   \n",
       "9  Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...   \n",
       "\n",
       "                      Company Name  \n",
       "0                            Wipro  \n",
       "1  TATA CONSULTANCY SERVICES (TCS)  \n",
       "2                       InnovAccer  \n",
       "3                       IHS Markit  \n",
       "4                Applied Materials  \n",
       "5                              PwC  \n",
       "6                            Wipro  \n",
       "7                              EXL  \n",
       "8                             PayU  \n",
       "9                Fractal Analytics  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['Job Title'] = title_tags1\n",
    "df1['Job Location'] = location1\n",
    "df1['Company Name'] = company1\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae5ab0e",
   "metadata": {},
   "source": [
    "Ques. 3\n",
    "You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:\n",
    "\n",
    "first get the webpage https://www.naukri.com/\n",
    "Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "Then click the search button.\n",
    "Then apply the location filter and salary filter by checking the respective boxes\n",
    "Then scrape the data for the first 10 jobs results you get.\n",
    "Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2665a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url2 = 'https://www.naukri.com/'\n",
    "driver.get(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "509fa85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_job2 = driver.find_element_by_class_name(\"suggestor-input \") #extracting element\n",
    "search_job2.send_keys(\"Data Scientist\") #Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3169c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn2 = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn2.click() #Clicking on the search Button')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7289bf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_check = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[1]/div[1]/div[1]/ul/li[3]/span')\n",
    "location_check.click() # Used location check to select “Delhi/NCR” and then we are clicking on to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "102a9c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_check = driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[1]/div[1]/div[1]/ul/li[2]/span')\n",
    "salary_check.click() # Used salary check to select “3-6” lakhs and then we are clicking o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89786b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "title_tags2 = []\n",
    "location2 = []\n",
    "company2 = []\n",
    "exper2 = []\n",
    "\n",
    "title_tag2= driver.find_elements_by_xpath('//a[@class = \"title fw500 ellipsis\"]')\n",
    "title2= title_tag2[0:10] #fixing the boundries(how much data we want to extract)\n",
    "loc2 = driver.find_elements_by_xpath('//li[@class = \"fleft grey-text br2 placeHolderLi location\"]')\n",
    "locc2 = loc2[0:10]\n",
    "com2 = driver.find_elements_by_xpath('//a[@class = \"subTitle ellipsis fleft\"]')\n",
    "comp2 = com2[0:10]\n",
    "exp2 = driver.find_elements_by_xpath('//li[@class = \"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "expp2 = exp2[0:10]\n",
    "\n",
    "for i in title2:\n",
    "    title_tags2.append(i.text) #appending the text in title_tags2 list\n",
    "for j in locc2:\n",
    "    location2.append(j.text) #Fetching location data\n",
    "for k in comp2:\n",
    "    company2.append(k.text)\n",
    "for l in expp2:\n",
    "    exper2.append(l.text)\n",
    "\n",
    "print(len(title_tags2))#priting title_tags2\n",
    "print(len(company2))\n",
    "print(len(location2))\n",
    "print(len(exper2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed31d302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Kochi/Cochin, New Delhi, Bangalore/Bengaluru, ...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>11-21 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Chennai, Bangal...</td>\n",
       "      <td>InnovAccer</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Research and Development -AI/ML -(PhD )</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>EXL</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Noida, Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>9-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opportunity For Data Scientist - Female Candid...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>PayU</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Consultant - Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Teleperformance (TP)</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "1                              Senior Data Scientist   \n",
       "2            Research and Development -AI/ML -(PhD )   \n",
       "3                       Senior Data Science Engineer   \n",
       "4                 Data Science - Engineering Manager   \n",
       "5  Opportunity For Data Scientist - Female Candid...   \n",
       "6                    DigitalBCG GAMMA Data Scientist   \n",
       "7                   Data Scientist - Noida/Bangalore   \n",
       "8                                     Data Scientist   \n",
       "9                        Consultant - Data Scientist   \n",
       "\n",
       "                                        Job Location             Company Name  \\\n",
       "0  Kochi/Cochin, New Delhi, Bangalore/Bengaluru, ...                    Wipro   \n",
       "1  Noida, Hyderabad/Secunderabad, Chennai, Bangal...               InnovAccer   \n",
       "2  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...                      EXL   \n",
       "3  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...        Fractal Analytics   \n",
       "4                 Noida, Mumbai, Bangalore/Bengaluru                    Paytm   \n",
       "5  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...                     PayU   \n",
       "6                     New Delhi, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "7                         Noida, Bangalore/Bengaluru                      EXL   \n",
       "8              Gurgaon/Gurugram, Bangalore/Bengaluru                      EXL   \n",
       "9                                   Gurgaon/Gurugram     Teleperformance (TP)   \n",
       "\n",
       "  Experience Required  \n",
       "0           11-21 Yrs  \n",
       "1             4-9 Yrs  \n",
       "2             4-8 Yrs  \n",
       "3             5-9 Yrs  \n",
       "4            9-13 Yrs  \n",
       "5             1-3 Yrs  \n",
       "6             2-5 Yrs  \n",
       "7            5-10 Yrs  \n",
       "8             4-7 Yrs  \n",
       "9            8-12 Yrs  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame()\n",
    "df2['Job Title'] = title_tags2\n",
    "df2['Job Location'] = location2\n",
    "df2['Company Name'] = company2\n",
    "df2['Experience Required'] = exper2\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75b7da3",
   "metadata": {},
   "source": [
    "Ques. 4\n",
    "Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "\n",
    "Brand\n",
    "Product Description\n",
    "Price To scrape the data you have to go through following steps:\n",
    "Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "Enter “sunglasses” in the search field where “search for products, brands andmore” is written and click the search icon\n",
    "After that you will reach to the page having a lot of sunglasses. From this pageyou can scrap the required data as usual.\n",
    "After scraping data from the first page, go to the “Next” Button at the bottom ofthe page , then click on it.\n",
    "Now scrape data from this page as usual\n",
    "Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db7c9bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "url3 = 'https://www.flipkart.com/'\n",
    "driver.get(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94afe299",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_class_name(\"_3704LK\") #extracting element\n",
    "search.send_keys(\"Sun Glasses\") #Entering data in search box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9de89d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_class_name('_1_3w1N')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60ef36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0 #start page\n",
    "end=3 #end page\n",
    "\n",
    "brand = []\n",
    "price = []\n",
    "des = []\n",
    "off = []\n",
    "\n",
    "for page in range(start,end): #for loop for scrapping 3 page\n",
    "    brands=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")#scraping brands name by class name\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    descp=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    dis=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']\")\n",
    "    \n",
    "    for i in brands:\n",
    "        brand.append(i.text) #appending the text in Brand list\n",
    "    for j in prices:\n",
    "        price.append(j.text)\n",
    "    for k in descp:\n",
    "        des.append(k.text)\n",
    "    for l in dis:\n",
    "        off.append(l.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//div[@class='_2t2dSp']\") #Scraping the list of buttons from the page\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0027df43",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    except:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "        driver.get(nxt_button[1].get_attribute('href')) #Getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fbc4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=brand[0:100]\n",
    "p=price[0:100]\n",
    "d=des[0:100]\n",
    "o=off[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c53b5124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " List of Brands:- \n",
      " []\n",
      "\n",
      " \n",
      "Product Description:- \n",
      " []\n",
      "\n",
      " \n",
      " Price:- \n",
      " []\n",
      "\n",
      " \n",
      " Discount:- \n",
      " []\n"
     ]
    }
   ],
   "source": [
    "print('\\n List of Brands:- \\n', b)\n",
    "print('\\n \\nProduct Description:- \\n', d)\n",
    "print('\\n \\n Price:- \\n', p)\n",
    "print('\\n \\n Discount:- \\n', o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae2d3274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand, Product Description, Price, Discount]\n",
       "Index: []"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.DataFrame() \n",
    "df3['Brand']=b\n",
    "df3['Product Description'] = d\n",
    "df3['Price']=p\n",
    "df3['Discount']=o\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919774f",
   "metadata": {},
   "source": [
    "Ques. 5\n",
    "Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\n",
    "\n",
    "You have to scrape the tick marked attributes.These are:\n",
    "\n",
    "Rating\n",
    "Review summary\n",
    "Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "504174f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\n",
    "driver.get(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f3c770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "next = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a/div/span')\n",
    "next.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36c7e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=11\n",
    "rating = []\n",
    "review = []\n",
    "full = []\n",
    "for page in range(start,end):\n",
    "    ratings=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    reviews=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    descp=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for i in ratings:\n",
    "        rating.append(i.text)\n",
    "    for j in reviews:\n",
    "        review.append(j.text)\n",
    "    for k in descp:\n",
    "        full.append(k.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5aa6aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr=rating[0:100]\n",
    "re=review[0:100]\n",
    "ff=full[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "445f8399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Undoubtedly Iphone 11 is the most successful m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Don’t expect much from front camera… especiall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>I purchased the iPhone 11 a month back. I must...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings              Reviews  \\\n",
       "0        5       Simply awesome   \n",
       "1        5     Perfect product!   \n",
       "2        5  Best in the market!   \n",
       "3        5   Highly recommended   \n",
       "4        5    Worth every penny   \n",
       "..     ...                  ...   \n",
       "95       5               Super!   \n",
       "96       5            Wonderful   \n",
       "97       5    Worth every penny   \n",
       "98       5  Best in the market!   \n",
       "99       5            Fabulous!   \n",
       "\n",
       "                                          Description  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "96  Nice value for money good and best price I pho...  \n",
       "97  Undoubtedly Iphone 11 is the most successful m...  \n",
       "98  Don’t expect much from front camera… especiall...  \n",
       "99  I purchased the iPhone 11 a month back. I must...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.DataFrame({'Ratings':rr,'Reviews':re,'Description':ff})\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84e4e3",
   "metadata": {},
   "source": [
    "Ques. 6\n",
    "Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the search field. You have to scrape 4 attributes of each sneaker:\n",
    "\n",
    "Brand\n",
    "Product Description\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "468bc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url5 = 'https://www.flipkart.com/'\n",
    "driver.get(url5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "278134f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_class_name(\"_3704LK\")\n",
    "search.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efa871d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_class_name('L0Z3Pu')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "49d1c9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "start=0\n",
    "end=3\n",
    "brand1 = []\n",
    "price1 = []\n",
    "des1 = []\n",
    "for page in range(start,end): #for loop for scrapping 3 page\n",
    "    brands1=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    prices1=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    descp1=driver.find_elements_by_class_name('IRpwTa')\n",
    "\n",
    "    for i in brands1:\n",
    "        brand1.append(i.text) #appending the text in Brands1 list\n",
    "    for j in prices1:\n",
    "        price1.append(j.text)\n",
    "    for k in descp1:\n",
    "        des1.append(k.text)\n",
    "        \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "print(len(brand1))\n",
    "print(len(price1))\n",
    "print(len(des1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16d056c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb=brand1[0:100]\n",
    "pp=price1[0:100]\n",
    "dd=des1[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1acad6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADIDAS ORIGINALS</td>\n",
       "      <td>STAN SMITH VULC Sneakers For Men</td>\n",
       "      <td>₹3,299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shoes Icon</td>\n",
       "      <td>DLS Fashionable Trandy Sports Shoes For Man's ...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absolute comfort</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Puma Smash v2 L Sneakers For Men</td>\n",
       "      <td>₹1,658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Love Wn s Sneakers For Women</td>\n",
       "      <td>₹1,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Graviton Pro Sneakers For Men</td>\n",
       "      <td>₹2,761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                Product Description  \\\n",
       "0   ADIDAS ORIGINALS                   STAN SMITH VULC Sneakers For Men   \n",
       "1         Shoes Icon  DLS Fashionable Trandy Sports Shoes For Man's ...   \n",
       "2   Absolute comfort                                   Sneakers For Men   \n",
       "3             BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men   \n",
       "4               PUMA                   Puma Smash v2 L Sneakers For Men   \n",
       "..               ...                                                ...   \n",
       "95              PUMA                       Love Wn s Sneakers For Women   \n",
       "96          Roadster                                   Sneakers For Men   \n",
       "97              aadi                                   Sneakers For Men   \n",
       "98              PUMA                      Graviton Pro Sneakers For Men   \n",
       "99          RapidBox                                   Sneakers For Men   \n",
       "\n",
       "     Price  \n",
       "0   ₹3,299  \n",
       "1     ₹399  \n",
       "2     ₹249  \n",
       "3     ₹284  \n",
       "4   ₹1,658  \n",
       "..     ...  \n",
       "95  ₹1,525  \n",
       "96    ₹959  \n",
       "97    ₹449  \n",
       "98  ₹2,761  \n",
       "99    ₹650  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5=pd.DataFrame()\n",
    "df5['Brand']=bb\n",
    "df5['Product Description'] = dd\n",
    "df5['Price']=pp\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e961c",
   "metadata": {},
   "source": [
    "Ques. 7\n",
    "Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, and then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5814cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "url6 = 'https://www.myntra.com/shoes'\n",
    "driver.get(url6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "576b8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#color check\n",
    "col = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "col.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5f4dc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#price check\n",
    "price_check = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div')\n",
    "price_check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "898ac708",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: cannot determine loading status\nfrom unknown error: unexpected command response\n  (Session info: chrome=103.0.5060.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x01296463+2188387]\n\tOrdinal0 [0x0122E461+1762401]\n\tOrdinal0 [0x01143D78+802168]\n\tOrdinal0 [0x01137210+750096]\n\tOrdinal0 [0x0113675A+747354]\n\tOrdinal0 [0x01135D3F+744767]\n\tOrdinal0 [0x01134C28+740392]\n\tOrdinal0 [0x01135228+741928]\n\tOrdinal0 [0x0113EF2F+782127]\n\tOrdinal0 [0x01149FBB+827323]\n\tOrdinal0 [0x0114D310+840464]\n\tOrdinal0 [0x011354F6+742646]\n\tOrdinal0 [0x01149BF3+826355]\n\tOrdinal0 [0x0119CF6D+1167213]\n\tOrdinal0 [0x0118C5F6+1099254]\n\tOrdinal0 [0x01166BE0+945120]\n\tOrdinal0 [0x01167AD6+948950]\n\tGetHandleVerifier [0x015371F2+2712546]\n\tGetHandleVerifier [0x0152886D+2652765]\n\tGetHandleVerifier [0x0132002A+520730]\n\tGetHandleVerifier [0x0131EE06+516086]\n\tOrdinal0 [0x0123468B+1787531]\n\tOrdinal0 [0x01238E88+1805960]\n\tOrdinal0 [0x01238F75+1806197]\n\tOrdinal0 [0x01241DF1+1842673]\n\tBaseThreadInitThunk [0x7642DEA4+36]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F00BE+670]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F008D+621]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4944/3012135929.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnxt_button\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#getting the link from the list for next page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4944/3012135929.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnxt_button\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#getting the link from the list for next page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnxt_button\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrand2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \"\"\"\n\u001b[1;32m--> 442\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    432\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: cannot determine loading status\nfrom unknown error: unexpected command response\n  (Session info: chrome=103.0.5060.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x01296463+2188387]\n\tOrdinal0 [0x0122E461+1762401]\n\tOrdinal0 [0x01143D78+802168]\n\tOrdinal0 [0x01137210+750096]\n\tOrdinal0 [0x0113675A+747354]\n\tOrdinal0 [0x01135D3F+744767]\n\tOrdinal0 [0x01134C28+740392]\n\tOrdinal0 [0x01135228+741928]\n\tOrdinal0 [0x0113EF2F+782127]\n\tOrdinal0 [0x01149FBB+827323]\n\tOrdinal0 [0x0114D310+840464]\n\tOrdinal0 [0x011354F6+742646]\n\tOrdinal0 [0x01149BF3+826355]\n\tOrdinal0 [0x0119CF6D+1167213]\n\tOrdinal0 [0x0118C5F6+1099254]\n\tOrdinal0 [0x01166BE0+945120]\n\tOrdinal0 [0x01167AD6+948950]\n\tGetHandleVerifier [0x015371F2+2712546]\n\tGetHandleVerifier [0x0152886D+2652765]\n\tGetHandleVerifier [0x0132002A+520730]\n\tGetHandleVerifier [0x0131EE06+516086]\n\tOrdinal0 [0x0123468B+1787531]\n\tOrdinal0 [0x01238E88+1805960]\n\tOrdinal0 [0x01238F75+1806197]\n\tOrdinal0 [0x01241DF1+1842673]\n\tBaseThreadInitThunk [0x7642DEA4+36]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F00BE+670]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F008D+621]\n"
     ]
    }
   ],
   "source": [
    "start=0\n",
    "end=3\n",
    "brand2 = []\n",
    "price2 = []\n",
    "des2 = []\n",
    "\n",
    "for page in range(start,end): #for loop for scrapping 3 page\n",
    "    brands2=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\") #scraping brands name by xpath\n",
    "    prices2=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    descp2=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "\n",
    "    for i in brands2:\n",
    "        brand2.append(i.text) #appending the text in Brands2\n",
    "    for j in prices2:\n",
    "        price2.append(j.text)\n",
    "    for k in descp2:\n",
    "        des2.append(k.text)\n",
    "\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@rel='next']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "print(len(brand2))\n",
    "print(len(price2))\n",
    "print(len(des2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04743a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "28b4bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbb= brand2[0:100]\n",
    "ppp=price2[0:100]\n",
    "ddd=des2[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eda0eb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short Shoe Description</th>\n",
       "      <th>Price of the Shoe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity 3 Running</td>\n",
       "      <td>Rs. 11196Rs. 13995(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 7999Rs. 15999(50% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men KD 15 Basketball Shoes</td>\n",
       "      <td>Rs. 11895Rs. 13995(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women React MR 3 Running Shoes</td>\n",
       "      <td>Rs. 8396Rs. 10495(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women React Escape Running</td>\n",
       "      <td>Rs. 9196Rs. 11495(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Free Metcon 4 Training</td>\n",
       "      <td>Rs. 8796Rs. 10995(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men HOVR Sonic SE Running Shoe</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Eternity Nitro Running Shoes</td>\n",
       "      <td>Rs. 9749Rs. 12999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 7649Rs. 8999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Defiant Generation Tennis</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Colourblocked Sneakers</td>\n",
       "      <td>Rs. 9175Rs. 10795(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Solar Glide 4 ST Running</td>\n",
       "      <td>Rs. 11249Rs. 14999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men MAX CUSHIONING ELITE-LUCID</td>\n",
       "      <td>Rs. 7599Rs. 9499(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Solid Oznova Sneakers</td>\n",
       "      <td>Rs. 10199Rs. 11999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men UA Charged Vantage 2 Run</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>PEAKFREAK OUTDRY Trekking Shoe</td>\n",
       "      <td>Rs. 9899Rs. 9999(1% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Adizero Boston 11 Running</td>\n",
       "      <td>Rs. 10499Rs. 13999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Velocity Nitro Running</td>\n",
       "      <td>Rs. 8999Rs. 11999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>New Balance</td>\n",
       "      <td>Men Woven Design Suede Sneakers</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Formal Derbys</td>\n",
       "      <td>Rs. 8499Rs. 9999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men JEANS RETRO BASKET Sneaker</td>\n",
       "      <td>Rs. 7309Rs. 8599(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women KarlieKlossX9000 Running</td>\n",
       "      <td>Rs. 8399Rs. 13999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Deviate Nitro Shoes</td>\n",
       "      <td>Rs. 10499Rs. 14999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 8499Rs. 9999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men M Nitro Running Shoess</td>\n",
       "      <td>Rs. 9099Rs. 12999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Charged Breeze Running</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women SL20.3 Running Shoes</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Hovr Sonic SE Run Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Lightweight Sneakers</td>\n",
       "      <td>Rs. 11990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women SN1997 Running Shoes</td>\n",
       "      <td>Rs. 7799Rs. 12999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Men GEL-Quantum 360 6 Sports</td>\n",
       "      <td>Rs. 13999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Ankle Boots</td>\n",
       "      <td>Rs. 9405Rs. 9900(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Textured Sneakers</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "      <td>Rs. 9891Rs. 10990(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Clarks</td>\n",
       "      <td>Men Leather Slip-Ons</td>\n",
       "      <td>Rs. 7899Rs. 9999(21% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Women Magnify Nitro Running</td>\n",
       "      <td>Rs. 9099Rs. 12999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>Women Trekking Shoes</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KIPRUN By Decathlon</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 10099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Unisex KING Pro 21 Football</td>\n",
       "      <td>Rs. 7499Rs. 9999(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Block Sandals</td>\n",
       "      <td>Rs. 9810Rs. 10900(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Velocity Nitro 2 Running</td>\n",
       "      <td>Rs. 7699Rs. 10999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>GEL-Pulse 13 Running Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Leather Block Sandals</td>\n",
       "      <td>Rs. 7693Rs. 10990(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Block Sandals with Buckles</td>\n",
       "      <td>Rs. 8505Rs. 10500(19% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men GENERATION ZEROGRAND STITCHLITE</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "      <td>Rs. 11192Rs. 13990(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Perforations Sneakers</td>\n",
       "      <td>Rs. 12591Rs. 13990(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Block Heeled Boots with Buckles</td>\n",
       "      <td>Rs. 10355Rs. 10900(5% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Textured Leather Sneakers</td>\n",
       "      <td>Rs. 9990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                   Short Shoe Description  \\\n",
       "0                   ALDO                      Men Leather Loafers   \n",
       "1                   Nike             Men React Infinity 3 Running   \n",
       "2                   ALDO                      Men Leather Loafers   \n",
       "3                   Nike               Men KD 15 Basketball Shoes   \n",
       "4                   Nike           Women React MR 3 Running Shoes   \n",
       "5                   Nike               Women React Escape Running   \n",
       "6                   Nike             Women Free Metcon 4 Training   \n",
       "7           UNDER ARMOUR           Men HOVR Sonic SE Running Shoe   \n",
       "8                   Puma             Eternity Nitro Running Shoes   \n",
       "9           Hush Puppies        Men Solid Leather Formal Slip-Ons   \n",
       "10                ADIDAS            Men Defiant Generation Tennis   \n",
       "11                  Nike               Men Colourblocked Sneakers   \n",
       "12                ADIDAS             Men Solar Glide 4 ST Running   \n",
       "13              Skechers           Men MAX CUSHIONING ELITE-LUCID   \n",
       "14      ADIDAS Originals                Men Solid Oznova Sneakers   \n",
       "15          UNDER ARMOUR             Men UA Charged Vantage 2 Run   \n",
       "16              Columbia           PEAKFREAK OUTDRY Trekking Shoe   \n",
       "17                ADIDAS            Men Adizero Boston 11 Running   \n",
       "18                  Puma               Men Velocity Nitro Running   \n",
       "19           New Balance          Men Woven Design Suede Sneakers   \n",
       "20          Hush Puppies                        Men Formal Derbys   \n",
       "21        Tommy Hilfiger           Men JEANS RETRO BASKET Sneaker   \n",
       "22                ADIDAS           Women KarlieKlossX9000 Running   \n",
       "23                  Puma                  Men Deviate Nitro Shoes   \n",
       "24          Hush Puppies        Men Solid Leather Formal Slip-Ons   \n",
       "25                  Puma               Men M Nitro Running Shoess   \n",
       "26          UNDER ARMOUR             Women Charged Breeze Running   \n",
       "27                ADIDAS               Women SL20.3 Running Shoes   \n",
       "28          UNDER ARMOUR            Women Hovr Sonic SE Run Shoes   \n",
       "29                  Geox                 Men Lightweight Sneakers   \n",
       "30                ADIDAS               Women SN1997 Running Shoes   \n",
       "31                 ASICS             Men GEL-Quantum 360 6 Sports   \n",
       "32               Saint G                      Leather Ankle Boots   \n",
       "33              Skechers                    Men Textured Sneakers   \n",
       "34                  Geox                     Men Leather Sneakers   \n",
       "35                Clarks                     Men Leather Slip-Ons   \n",
       "36                  Puma              Women Magnify Nitro Running   \n",
       "37              Columbia                     Women Trekking Shoes   \n",
       "38   KIPRUN By Decathlon                        Men Running Shoes   \n",
       "39                  Puma              Unisex KING Pro 21 Football   \n",
       "40               Saint G                    Leather Block Sandals   \n",
       "41                  Puma             Men Velocity Nitro 2 Running   \n",
       "42                 ASICS               GEL-Pulse 13 Running Shoes   \n",
       "43                  Geox                    Leather Block Sandals   \n",
       "44               Saint G       Leather Block Sandals with Buckles   \n",
       "45             Cole Haan      Men GENERATION ZEROGRAND STITCHLITE   \n",
       "46  Heel & Buckle London                     Men Leather Sneakers   \n",
       "47                  Geox                Men Perforations Sneakers   \n",
       "48               Saint G  Leather Block Heeled Boots with Buckles   \n",
       "49                  Geox            Men Textured Leather Sneakers   \n",
       "\n",
       "              Price of the Shoe  \n",
       "0    Rs. 7799Rs. 12999(40% OFF)  \n",
       "1   Rs. 11196Rs. 13995(20% OFF)  \n",
       "2    Rs. 7999Rs. 15999(50% OFF)  \n",
       "3   Rs. 11895Rs. 13995(15% OFF)  \n",
       "4    Rs. 8396Rs. 10495(20% OFF)  \n",
       "5    Rs. 9196Rs. 11495(20% OFF)  \n",
       "6    Rs. 8796Rs. 10995(20% OFF)  \n",
       "7                      Rs. 9999  \n",
       "8    Rs. 9749Rs. 12999(25% OFF)  \n",
       "9     Rs. 7649Rs. 8999(15% OFF)  \n",
       "10                     Rs. 9999  \n",
       "11   Rs. 9175Rs. 10795(15% OFF)  \n",
       "12  Rs. 11249Rs. 14999(25% OFF)  \n",
       "13    Rs. 7599Rs. 9499(20% OFF)  \n",
       "14  Rs. 10199Rs. 11999(15% OFF)  \n",
       "15                     Rs. 7999  \n",
       "16     Rs. 9899Rs. 9999(1% OFF)  \n",
       "17  Rs. 10499Rs. 13999(25% OFF)  \n",
       "18   Rs. 8999Rs. 11999(25% OFF)  \n",
       "19   Rs. 7799Rs. 12999(40% OFF)  \n",
       "20    Rs. 8499Rs. 9999(15% OFF)  \n",
       "21    Rs. 7309Rs. 8599(15% OFF)  \n",
       "22   Rs. 8399Rs. 13999(40% OFF)  \n",
       "23  Rs. 10499Rs. 14999(30% OFF)  \n",
       "24    Rs. 8499Rs. 9999(15% OFF)  \n",
       "25   Rs. 9099Rs. 12999(30% OFF)  \n",
       "26                     Rs. 8999  \n",
       "27                    Rs. 11999  \n",
       "28                     Rs. 9999  \n",
       "29                    Rs. 11990  \n",
       "30   Rs. 7799Rs. 12999(40% OFF)  \n",
       "31                    Rs. 13999  \n",
       "32     Rs. 9405Rs. 9900(5% OFF)  \n",
       "33                     Rs. 7999  \n",
       "34   Rs. 9891Rs. 10990(10% OFF)  \n",
       "35    Rs. 7899Rs. 9999(21% OFF)  \n",
       "36   Rs. 9099Rs. 12999(30% OFF)  \n",
       "37                     Rs. 8999  \n",
       "38                    Rs. 10099  \n",
       "39    Rs. 7499Rs. 9999(25% OFF)  \n",
       "40   Rs. 9810Rs. 10900(10% OFF)  \n",
       "41   Rs. 7699Rs. 10999(30% OFF)  \n",
       "42                     Rs. 7999  \n",
       "43   Rs. 7693Rs. 10990(30% OFF)  \n",
       "44   Rs. 8505Rs. 10500(19% OFF)  \n",
       "45                    Rs. 11999  \n",
       "46  Rs. 11192Rs. 13990(20% OFF)  \n",
       "47  Rs. 12591Rs. 13990(10% OFF)  \n",
       "48   Rs. 10355Rs. 10900(5% OFF)  \n",
       "49                     Rs. 9990  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = pd.DataFrame()\n",
    "df6['Brand']=bbb\n",
    "df6['Short Shoe Description'] = ddd\n",
    "df6['Price of the Shoe'] = ppp\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580bc8ae",
   "metadata": {},
   "source": [
    "Ques. 8\n",
    "Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "\n",
    "Title\n",
    "Ratings\n",
    "Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f336f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url7 = 'https://www.amazon.in/'\n",
    "driver.get(url7) #opening the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f65ff0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search.send_keys('Laptop') #Sending the keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45c279b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "butt=driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "butt.click() #clicking on the search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "58eaf835",
   "metadata": {},
   "outputs": [],
   "source": [
    "i7=driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "i7.click() # Currectly Check box was not available here in the website so, first scrapping data for i7 then for i9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e9fc4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping the price for 1st 10 laptop's\n",
    "pri = []\n",
    "pric=driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "for i in pric:\n",
    "    pri.append(i.text) #appending text\n",
    "p= pri[0:10] #Fixing the limit(only 10 laptops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d336aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating the url's for each laptop's\n",
    "urls=driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a\")\n",
    "UR=[]\n",
    "for i in urls[0:10]:\n",
    "    UR.append(i.get_attribute('href')) #getting the url of first 10 laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf702873",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: cannot determine loading status\nfrom unknown error: unexpected command response\n  (Session info: chrome=103.0.5060.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x01296463+2188387]\n\tOrdinal0 [0x0122E461+1762401]\n\tOrdinal0 [0x01143D78+802168]\n\tOrdinal0 [0x01137210+750096]\n\tOrdinal0 [0x0113675A+747354]\n\tOrdinal0 [0x01135D3F+744767]\n\tOrdinal0 [0x01134C28+740392]\n\tOrdinal0 [0x01135228+741928]\n\tOrdinal0 [0x0113EF2F+782127]\n\tOrdinal0 [0x01149FBB+827323]\n\tOrdinal0 [0x0114D310+840464]\n\tOrdinal0 [0x011354F6+742646]\n\tOrdinal0 [0x01149BF3+826355]\n\tOrdinal0 [0x0119CF6D+1167213]\n\tOrdinal0 [0x0118C5F6+1099254]\n\tOrdinal0 [0x01166BE0+945120]\n\tOrdinal0 [0x01167AD6+948950]\n\tGetHandleVerifier [0x015371F2+2712546]\n\tGetHandleVerifier [0x0152886D+2652765]\n\tGetHandleVerifier [0x0132002A+520730]\n\tGetHandleVerifier [0x0131EE06+516086]\n\tOrdinal0 [0x0123468B+1787531]\n\tOrdinal0 [0x01238E88+1805960]\n\tOrdinal0 [0x01238F75+1806197]\n\tOrdinal0 [0x01241DF1+1842673]\n\tBaseThreadInitThunk [0x7642DEA4+36]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F00BE+670]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F008D+621]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4944/3502467233.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mUR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m#here i used try and except because there were few laptops where ratings were not there in the website\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//span[@class='a-size-base a-nowrap']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mrating\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m         \"\"\"\n\u001b[1;32m--> 442\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    432\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: cannot determine loading status\nfrom unknown error: unexpected command response\n  (Session info: chrome=103.0.5060.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x01296463+2188387]\n\tOrdinal0 [0x0122E461+1762401]\n\tOrdinal0 [0x01143D78+802168]\n\tOrdinal0 [0x01137210+750096]\n\tOrdinal0 [0x0113675A+747354]\n\tOrdinal0 [0x01135D3F+744767]\n\tOrdinal0 [0x01134C28+740392]\n\tOrdinal0 [0x01135228+741928]\n\tOrdinal0 [0x0113EF2F+782127]\n\tOrdinal0 [0x01149FBB+827323]\n\tOrdinal0 [0x0114D310+840464]\n\tOrdinal0 [0x011354F6+742646]\n\tOrdinal0 [0x01149BF3+826355]\n\tOrdinal0 [0x0119CF6D+1167213]\n\tOrdinal0 [0x0118C5F6+1099254]\n\tOrdinal0 [0x01166BE0+945120]\n\tOrdinal0 [0x01167AD6+948950]\n\tGetHandleVerifier [0x015371F2+2712546]\n\tGetHandleVerifier [0x0152886D+2652765]\n\tGetHandleVerifier [0x0132002A+520730]\n\tGetHandleVerifier [0x0131EE06+516086]\n\tOrdinal0 [0x0123468B+1787531]\n\tOrdinal0 [0x01238E88+1805960]\n\tOrdinal0 [0x01238F75+1806197]\n\tOrdinal0 [0x01241DF1+1842673]\n\tBaseThreadInitThunk [0x7642DEA4+36]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F00BE+670]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F008D+621]\n"
     ]
    }
   ],
   "source": [
    "rating=[]\n",
    "nam = []\n",
    "\n",
    "for i in UR:    \n",
    "    try:   #here i used try and except because there were few laptops where ratings were not there in the website\n",
    "        driver.get(i)\n",
    "        rate=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']\")\n",
    "        rating.append(rate.text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append(\"NO rating\")\n",
    "\n",
    "for j in UR:\n",
    "    try:\n",
    "        driver.get(j)\n",
    "        name=driver.find_element_by_xpath('//span[@class=\"a-size-large product-title-word-break\"]')\n",
    "        nam.append(name.text.split(',')[0].replace(',','\\n'))\n",
    "    except NoSuchElementException:\n",
    "        rating.append(\"No Title available\")\n",
    "\n",
    "print(len(rating))\n",
    "print(len(nam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "735fc11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Name Of Laptop's :-\n",
      " \n",
      " []\n",
      "\n",
      "\n",
      " Rating's of Each Laptop :- \n",
      " \n",
      " ['4.3 out of 5', '1.8 out of 5', '4.1 out of 5']\n",
      "\n",
      "\n",
      " Price of Laptop's :- \n",
      " \n",
      " ['45,603', '36,350', '25,990', '29,490', '22,990', '25,490', '71,100', '68,000', '', '28,980']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Name Of Laptop's :-\\n \\n\", nam )\n",
    "print(\"\\n\\n Rating's of Each Laptop :- \\n \\n\", rating)\n",
    "print(\"\\n\\n Price of Laptop's :- \\n \\n\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "daf4c05f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4944/2242890971.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf7\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Name of laptops'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Ratings of the Laptops'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrating\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Price of the Laptops'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df7 = pd.DataFrame({'Name of laptops':nam,'Ratings of the Laptops':rating,'Price of the Laptops':p})\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1bda0b",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps:\n",
    "\n",
    "First get the webpage https://www.ambitionbox.com/\n",
    "Click on the Job option\n",
    "After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button.\n",
    "You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”.\n",
    "Then scrape the data for the first 10 jobs results.\n",
    "Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "884e10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url8 = 'https://www.ambitionbox.com/'\n",
    "driver.get(url8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9c0a3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "job= driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[6]')\n",
    "job.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d2268bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sear = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "sear.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2023ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "butto=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button/span')\n",
    "butto.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10ac18ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loca=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[2]/div[2]/div/div[1]/div[1]/div[3]/div/div[2]/p')\n",
    "loca.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4cd44933",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[2]/div[2]/div/div[1]/div[1]/div[3]/div/div[2]/input\"}\n  (Session info: chrome=103.0.5060.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x01296463+2188387]\n\tOrdinal0 [0x0122E461+1762401]\n\tOrdinal0 [0x01143D78+802168]\n\tOrdinal0 [0x01171880+989312]\n\tOrdinal0 [0x01171B1B+989979]\n\tOrdinal0 [0x0119E912+1173778]\n\tOrdinal0 [0x0118C824+1099812]\n\tOrdinal0 [0x0119CC22+1166370]\n\tOrdinal0 [0x0118C5F6+1099254]\n\tOrdinal0 [0x01166BE0+945120]\n\tOrdinal0 [0x01167AD6+948950]\n\tGetHandleVerifier [0x015371F2+2712546]\n\tGetHandleVerifier [0x0152886D+2652765]\n\tGetHandleVerifier [0x0132002A+520730]\n\tGetHandleVerifier [0x0131EE06+516086]\n\tOrdinal0 [0x0123468B+1787531]\n\tOrdinal0 [0x01238E88+1805960]\n\tOrdinal0 [0x01238F75+1806197]\n\tOrdinal0 [0x01241DF1+1842673]\n\tBaseThreadInitThunk [0x7642DEA4+36]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F00BE+670]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F008D+621]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4944/2209411544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/html/body/div/div/div/div[2]/div[1]/div[2]/div[2]/div[2]/div/div[1]/div[1]/div[3]/div/div[2]/input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Noida'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    524\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         )\n\u001b[1;32m--> 526\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m   1252\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    432\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[2]/div[2]/div/div[1]/div[1]/div[3]/div/div[2]/input\"}\n  (Session info: chrome=103.0.5060.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x01296463+2188387]\n\tOrdinal0 [0x0122E461+1762401]\n\tOrdinal0 [0x01143D78+802168]\n\tOrdinal0 [0x01171880+989312]\n\tOrdinal0 [0x01171B1B+989979]\n\tOrdinal0 [0x0119E912+1173778]\n\tOrdinal0 [0x0118C824+1099812]\n\tOrdinal0 [0x0119CC22+1166370]\n\tOrdinal0 [0x0118C5F6+1099254]\n\tOrdinal0 [0x01166BE0+945120]\n\tOrdinal0 [0x01167AD6+948950]\n\tGetHandleVerifier [0x015371F2+2712546]\n\tGetHandleVerifier [0x0152886D+2652765]\n\tGetHandleVerifier [0x0132002A+520730]\n\tGetHandleVerifier [0x0131EE06+516086]\n\tOrdinal0 [0x0123468B+1787531]\n\tOrdinal0 [0x01238E88+1805960]\n\tOrdinal0 [0x01238F75+1806197]\n\tOrdinal0 [0x01241DF1+1842673]\n\tBaseThreadInitThunk [0x7642DEA4+36]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F00BE+670]\n\tRtlInitializeCriticalSectionAndSpinCount [0x770F008D+621]\n"
     ]
    }
   ],
   "source": [
    "ty=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[2]/div[2]/div/div[1]/div[1]/div[3]/div/div[2]/input')\n",
    "ty.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "115e7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cli=driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button')\n",
    "cli.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef9a38a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "20\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading = []\n",
    "names = []\n",
    "days = []\n",
    "ratings = []\n",
    "head=driver.find_elements_by_xpath(\"//a[@class='title noclick']\")#scraping brands name by class name='_2WkVRV'\n",
    "name=driver.find_elements_by_xpath(\"//p[@class='company body-medium']\")\n",
    "day =driver.find_elements_by_xpath(\"//span[@class='body-small-l']\")\n",
    "rat =driver.find_elements_by_xpath(\"//span[@class='body-small']\")\n",
    "for i in head:\n",
    "    heading.append(i.text)\n",
    "for j in name:\n",
    "    names.append(j.text)\n",
    "for k in day:\n",
    "    days.append(k.text)\n",
    "for l in rat:\n",
    "    ratings.append(l.text)\n",
    "print(len(heading))\n",
    "print(len(names))\n",
    "print(len(days))\n",
    "print(len(ratings))\n",
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "806e3251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amazon',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Schneider Electric India Pvt. Ltd.',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'Walmart Labs',\n",
       " 'Shell India Markets Private Limited',\n",
       " 'IBM India Pvt. Limited',\n",
       " 'IBM India Pvt. Limited']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "363ed3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amazon - Manager - Business Intelligence (8-12 yrs)',\n",
       " 'Data Scientist: Artificial Intelligence',\n",
       " 'Data Scientist: Advanced Analytics',\n",
       " 'Principal - Data Scientist',\n",
       " 'Data Scientist: Artificial Intelligence',\n",
       " 'Data Scientist: Artificial Intelligence',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9a395f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3hr ago',\n",
       " '2d ago',\n",
       " '3d ago',\n",
       " '3d ago',\n",
       " '3d ago',\n",
       " '3d ago',\n",
       " '3d ago',\n",
       " '3d ago',\n",
       " '6d ago',\n",
       " '6d ago']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=days[0:20:2]#Extracting the required data\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cd9ce3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.2', '4.2', '4.2', '4.2', '4.2', '4.2', '4.2', '4.4', '4.2', '4.2']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "af69d599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of days ago when job was posted</th>\n",
       "      <th>Rating of the company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>3hr ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schneider Electric India Pvt. Ltd.</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Walmart Labs</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>6d ago</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Company Name No. of days ago when job was posted  \\\n",
       "0                               Amazon                             3hr ago   \n",
       "1               IBM India Pvt. Limited                              2d ago   \n",
       "2               IBM India Pvt. Limited                              3d ago   \n",
       "3   Schneider Electric India Pvt. Ltd.                              3d ago   \n",
       "4               IBM India Pvt. Limited                              3d ago   \n",
       "5               IBM India Pvt. Limited                              3d ago   \n",
       "6                         Walmart Labs                              3d ago   \n",
       "7  Shell India Markets Private Limited                              3d ago   \n",
       "8               IBM India Pvt. Limited                              6d ago   \n",
       "9               IBM India Pvt. Limited                              6d ago   \n",
       "\n",
       "  Rating of the company  \n",
       "0                   4.2  \n",
       "1                   4.2  \n",
       "2                   4.2  \n",
       "3                   4.2  \n",
       "4                   4.2  \n",
       "5                   4.2  \n",
       "6                   4.2  \n",
       "7                   4.4  \n",
       "8                   4.2  \n",
       "9                   4.2  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8 =pd.DataFrame()\n",
    "df8['Company Name'] = names\n",
    "df8['No. of days ago when job was posted'] = d\n",
    "df8['Rating of the company'] = ratings\n",
    "df8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a7a0c",
   "metadata": {},
   "source": [
    "Ques. 10\n",
    "Write a python program to scrape the salary data for Data Scientist designation. You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. The above task will be, done as shown in the below steps:\n",
    "\n",
    "First get the webpage https://www.ambitionbox.com/\n",
    "Click on the salaries option\n",
    "After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.\n",
    "Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "52cfc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url9 = 'https://www.ambitionbox.com/'\n",
    "driver.get(url9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6f1ebbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "sal.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "085df73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sea=driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "sea.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eb91fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc=driver.find_element_by_xpath(\"//div[@class='suggestion']\")\n",
    "cc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "85b5cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = []\n",
    "minn = []\n",
    "maax = []\n",
    "avg = []\n",
    "bas = []\n",
    "exp = []\n",
    "\n",
    "sall= driver.find_elements_by_class_name('name') #scraping by class name\n",
    "miin = driver.find_elements_by_class_name('salary-values')\n",
    "mixx= driver.find_elements_by_class_name('salary-values')\n",
    "avgg= driver.find_elements_by_class_name('averageCtc')\n",
    "base= driver.find_elements_by_class_name('name')\n",
    "expp= driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')\n",
    "\n",
    "for i in sall:\n",
    "    sal.append(i.text.split('\\n')[0])  #Spliting the data and fetching the required data what we want.\n",
    "for j in miin:\n",
    "    minn.append(j.text.split('\\n')[0])\n",
    "for k in mixx:\n",
    "    maax.append(k.text.split('\\n')[1])\n",
    "for l in avgg:\n",
    "    avg.append(l.text)\n",
    "\n",
    "for m in base:\n",
    "    bas.append(m.text.split('\\n')[-1])\n",
    "b =bas[0:10]\n",
    "for n in expp:\n",
    "    exp.append(n.text.split('\\n')[-1])\n",
    "    \n",
    "s= sal[0:10] #Fixing the limit of the data that we want\n",
    "mx = maax[0:10]\n",
    "mi = minn[0:10]\n",
    "a = avg[0:10]\n",
    "e=exp[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "580cd101",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4944/855092045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf9\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Company Name'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Number of salaries'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Minimum Salary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Average Salary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Maximum Salary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Experience Required'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "df9 = pd.DataFrame({'Company Name':s,'Number of salaries':b,'Minimum Salary':mi,'Average Salary':a,'Maximum Salary':mx,'Experience Required':e})\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
